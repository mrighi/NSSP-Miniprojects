{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess the data: copied from notebook 4 of exercises from week 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading ... \n",
      "\n",
      "================== Subject2 loaded. ==================\n",
      "================== Subject21 loaded. ==================\n",
      "================== Working on Pig p2-t2 ==================\n",
      "================== Working on Pig p6-t6 ==================\n"
     ]
    }
   ],
   "source": [
    "# data_path = ''\n",
    "fs = 24400 # Hz\n",
    "\n",
    "# Subjects\n",
    "n_subjects = 2\n",
    "subjs_info_loading = {'Subject2' : {'Name' : 'p2-t2', 'Vars' : ['Baseline', 'Angio36', 'RR15', 'TV500']},\n",
    "                      'Subject21' : {'Name' : 'p6-t6', 'Vars' : ['Baseline', 'Angio36', 'RR15', 'TV125']}\n",
    "                     }\n",
    "subjs_info_final = {'Subject2' : {'Name' : 'p2-t2', 'Vars' : ['Baseline', 'Angio36', 'RRC', 'TVC']},\n",
    "                    'Subject21' : {'Name' : 'p6-t6', 'Vars' : ['Baseline', 'Angio36', 'RRC', 'TVC']}\n",
    "                   }\n",
    "animals_labels = ['p2-t2', 'p6-t6']\n",
    "\n",
    "def load_data_all_subjects(subjs_info_loading, subjs_info_final, fs, type_data = 'Field_Data_Neuro'):\n",
    "    subjects_names = list(subjs_info_loading.keys())\n",
    "    subjs_info = subjs_info_final\n",
    "    all_data = {}\n",
    "    print('Start loading ... \\n')\n",
    "    for subject in subjects_names:\n",
    "        name_subj, data_struct = load_data_one_subject(subject, subjs_info_loading, fs, type_data = type_data)\n",
    "        all_data[name_subj] = data_struct\n",
    "        print('================== %s loaded. =================='%subject)\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def load_data_one_subject(subject, subjs_info_loading, fs, type_data = 'Field_Data_Neuro'):\n",
    "    name_subj_to_stock = subjs_info_loading[subject]['Name']\n",
    "    vars_to_load = subjs_info_loading[subject]['Vars']\n",
    "    data_struct = {}\n",
    "    \n",
    "    # file = h5py.File('data\\\\' + subject + '.mat','r')\n",
    "    file = h5py.File(subject + '.mat','r')\n",
    "    \n",
    "    # To get the names of the fields after decoding ASCII\n",
    "    all_field_names = get_field_names(file)\n",
    "\n",
    "    for var in vars_to_load:\n",
    "        id_field = np.where(all_field_names == var)[0]\n",
    "        curr_reference_data1 = file['Vagus_Data_Stimuli'][type_data][id_field][0][0]\n",
    "        curr_reference_data2 = file[curr_reference_data1][0][0]\n",
    "        final_data = np.transpose(np.asarray(file[curr_reference_data2]))\n",
    "        \n",
    "        if var == 'TV800' or var == 'TV500' or var == 'TV125': \n",
    "            var_name = 'TVC'\n",
    "        elif var == 'RR15' or var == 'RR20': \n",
    "            var_name = 'RRC'\n",
    "        else:\n",
    "            var_name = var\n",
    "            \n",
    "        data_struct[var_name] = {}\n",
    "        data_struct[var_name]['Data'] = final_data\n",
    "        n_time_pts = np.shape(final_data)[-1]\n",
    "        data_struct[var_name]['Time_pts'] = np.linspace(0, n_time_pts/fs, n_time_pts)\n",
    "        \n",
    "    return name_subj_to_stock, data_struct\n",
    "\n",
    "def get_field_names(file):\n",
    "    n_fields,_ = np.shape(file['Vagus_Data_Stimuli']['stimuli_name'])\n",
    "    all_field_names = []\n",
    "    for field in range(n_fields):\n",
    "        curr_reference_field = file['Vagus_Data_Stimuli']['stimuli_name'][field][0]\n",
    "        curr_field_ASCII = file[curr_reference_field]\n",
    "        curr_field = decode_ASCII(curr_field_ASCII)\n",
    "        all_field_names.append(curr_field)\n",
    "    return np.asarray(all_field_names)\n",
    "\n",
    "\n",
    "def decode_ASCII(numbers_array):\n",
    "    name = ''\n",
    "    squeezed_numbers = np.squeeze(numbers_array)\n",
    "    for n in squeezed_numbers:\n",
    "        name += chr(n)\n",
    "    return name\n",
    "\n",
    "data = load_data_all_subjects(subjs_info_loading, subjs_info_final, fs)\n",
    "print('Loading completed \\n')\n",
    "\n",
    "#print('Showing the data file:')\n",
    "#for key1 in data.keys():\n",
    "#    print('=========== %s ==========='%key1)\n",
    "#    for key2 in data[key1].keys():\n",
    "#        print('--- %s'%key2)\n",
    "#        for key3 in data[key1][key2].keys():\n",
    "#            print(' - %s'%key3)\n",
    "#            print('Shape : ', np.shape(data[key1][key2][key3]))\n",
    "\n",
    "def cut_all_data_to_established_duration_per_challenge(data):\n",
    "    '''\n",
    "    This function is a wrap-up to the function 'cut_data_one_pig_to_established_duration_per_challenge'.\n",
    "    '''\n",
    "    \n",
    "    new_data_struct = {}\n",
    "    for pig in data.keys():\n",
    "        print('================== Working on Pig %s =================='%pig)\n",
    "        data_curr_pig = data[pig]\n",
    "        data_curr_pig_cut = cut_data_one_pig_to_established_duration_per_challenge(data_curr_pig)\n",
    "        new_data_struct[pig] = data_curr_pig_cut\n",
    "        \n",
    "    return new_data_struct\n",
    "\n",
    "\n",
    "def cut_data_one_pig_to_established_duration_per_challenge(data_one_pig):\n",
    "    ''' \n",
    "    This function is used to cut the data for each challenge to the duration shown in Suppl. Table 1 in Vallone et al., 2021. \n",
    "    We take the first part of the data for each challenge (arbitrary choice). \n",
    "    '''\n",
    "    new_struct = copy.deepcopy(data_one_pig)\n",
    "    \n",
    "    dur_baseline = 5 #min\n",
    "    dur_RRC = 2 #min\n",
    "    dur_TVC = 2 #min\n",
    "    \n",
    "    for challenge in new_struct.keys():\n",
    "        data_curr_chal = new_struct[challenge]['Data']\n",
    "        time_pts_curr_chal = new_struct[challenge]['Time_pts']\n",
    "        t_end_sec = time_pts_curr_chal[-1]\n",
    "        \n",
    "        if challenge == 'Baseline': t_end_sec = dur_baseline * 60\n",
    "        elif challenge == 'RRC': t_end_sec = dur_RRC * 60\n",
    "        elif challenge == 'TVC': t_end_sec = dur_TVC * 60\n",
    "            \n",
    "#         print('Challenge %s , t_end_sec %0.3f'%(challenge, t_end_sec))\n",
    "            \n",
    "        id_t_end_curr_chal = find_specific_time_index(time_pts_curr_chal, t_end_sec)\n",
    "        new_struct[challenge]['Data'] = data_curr_chal[:,:id_t_end_curr_chal]\n",
    "        new_struct[challenge]['Time_pts'] = time_pts_curr_chal[:id_t_end_curr_chal]\n",
    "    \n",
    "    return new_struct\n",
    "\n",
    "def find_specific_time_index(time_pts, t):\n",
    "    t_id = np.argmin(np.abs(time_pts - t))\n",
    "    return t_id\n",
    "\n",
    "print('Start cutting data ... \\n')\n",
    "cut_data = cut_all_data_to_established_duration_per_challenge(data)\n",
    "print('Data cutting completed \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now now have ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the data files:\n",
      "=========== p2-t2 ===========\n",
      "--- Baseline\n",
      " - Data\n",
      "Shape :  (8, 7319999) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (7319999,) , type:  <class 'numpy.ndarray'>\n",
      "--- Angio36\n",
      " - Data\n",
      "Shape :  (8, 14780415) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (14780415,) , type:  <class 'numpy.ndarray'>\n",
      "--- RRC\n",
      " - Data\n",
      "Shape :  (8, 2927999) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (2927999,) , type:  <class 'numpy.ndarray'>\n",
      "--- TVC\n",
      " - Data\n",
      "Shape :  (8, 2927999) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (2927999,) , type:  <class 'numpy.ndarray'>\n",
      "=========== p6-t6 ===========\n",
      "--- Baseline\n",
      " - Data\n",
      "Shape :  (16, 7319999) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (7319999,) , type:  <class 'numpy.ndarray'>\n",
      "--- Angio36\n",
      " - Data\n",
      "Shape :  (16, 14940159) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (14940159,) , type:  <class 'numpy.ndarray'>\n",
      "--- RRC\n",
      " - Data\n",
      "Shape :  (16, 2927999) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (2927999,) , type:  <class 'numpy.ndarray'>\n",
      "--- TVC\n",
      " - Data\n",
      "Shape :  (16, 2927999) , type:  <class 'numpy.ndarray'>\n",
      " - Time_pts\n",
      "Shape :  (2927999,) , type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Showing the data files:')\n",
    "for key1 in cut_data.keys():\n",
    "    print('=========== %s ==========='%key1)\n",
    "    for key2 in cut_data[key1].keys():\n",
    "        print('--- %s'%key2)\n",
    "        for key3 in cut_data[key1][key2].keys():\n",
    "            print(' - %s'%key3)\n",
    "            print('Shape : ', np.shape(cut_data[key1][key2][key3]), ', type: ', type(cut_data[key1][key2][key3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 4.09836121e-05 8.19672243e-05 1.22950836e-04\n",
      " 1.63934449e-04 2.04918061e-04 2.45901673e-04 2.86885285e-04\n",
      " 3.27868897e-04 3.68852509e-04]\n",
      "299.9999589273583\n"
     ]
    }
   ],
   "source": [
    "t = cut_data['p2-t2']['Baseline']['Time_pts']\n",
    "print(t[0:10])\n",
    "print(t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "\n",
    "t = cut_data['p2-t2']['Baseline']['Time_pts']\n",
    "neur = cut_data['p2-t2']['Baseline']['Data']\n",
    "N = t.shape\n",
    "neur_f = scipy.fftpack.fft(neur)\n",
    "tf = np.linspace(0.0, 1.0/(2.0*), N//2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tf, 2.0/N * np.abs(neur_f[:N//2]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "548cb84f3c3c3a027d09fd18aa2745d959a35cd8c151ed2c8b5f74a76b0084e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
